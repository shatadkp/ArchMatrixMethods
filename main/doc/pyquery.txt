# Query to get machine statuses
status_query = """
PREFIX : <http://api.stardog.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?status ?status_label ?start ?end WHERE {
  ?status a :Stasis_of_Machine_Operationality ;
          :has_participant :USA0640_5290_PR5OkumaCNCGrinder_Grinder ;
          :occupies_temporal_region ?interval ;
          rdfs:label ?status_label .
  ?interval :start_time ?start ;
            :end_time ?end .
}
ORDER BY ?start
"""

# Execute query
csv_results = connection.select(status_query, content_type='text/csv')
df_statuses = pd.read_csv(io.BytesIO(csv_results))

# Parse start and end times with UTC parsing
df_statuses['start'] = pd.to_datetime(df_statuses['start'], utc=True)
df_statuses['end'] = pd.to_datetime(df_statuses['end'], utc=True)

# Get date range
start_date = df_statuses['start'].dt.date.min()
end_date = df_statuses['end'].dt.date.max()



=========================================

===============================


# Query to get shifts
shift_query = """
PREFIX : <http://api.stardog.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?shift ?shift_label ?shift_start ?shift_end WHERE {
  :USA0640_5290_PR5OkumaCNCGrinder_Grinder :participates_in ?act_of_manufacturing .
  ?act_of_manufacturing :is_temporal_region_of ?shift .
  ?shift rdfs:label ?shift_label ;
         :start_time ?shift_start ;
         :end_time ?shift_end .
}
"""

# Execute query
csv_results = connection.select(shift_query, content_type='text/csv')
df_shifts = pd.read_csv(io.BytesIO(csv_results))

# Parse shift start and end times
df_shifts['shift_start'] = pd.to_datetime(df_shifts['shift_start'], format='%H:%M:%S').dt.time
df_shifts['shift_end'] = pd.to_datetime(df_shifts['shift_end'], format='%H:%M:%S').dt.time

# Generate date range
date_range = pd.date_range(start_date, end_date)

# Function to generate shift intervals
def generate_shift_intervals(df_shifts, date_range):
    shift_intervals = []
    for date in date_range:
        for idx, shift in df_shifts.iterrows():
            shift_label = shift['shift_label']
            shift_start = shift['shift_start']
            shift_end = shift['shift_end']
            shift_name = shift['shift']
            
            start_datetime = datetime.combine(date, shift_start)
            end_datetime = datetime.combine(date, shift_end)
            if shift_end <= shift_start:
                # Shift crosses midnight
                end_datetime += timedelta(days=1)
            shift_intervals.append({
                'shift': shift_name,
                'shift_label': f"{shift_label} ({date.date()})",
                'shift_start': start_datetime,
                'shift_end': end_datetime
            })
    return pd.DataFrame(shift_intervals)

# Generate shift intervals
df_shift_intervals = generate_shift_intervals(df_shifts, date_range)

# Prepare for cross join
df_statuses['key'] = 1
df_shift_intervals['key'] = 1

# Cross join to combine statuses and shifts
df_cross = pd.merge(df_statuses, df_shift_intervals, on='key')

# Function to compute overlap
def compute_overlap(start1, end1, start2, end2):
    latest_start = max(start1, start2)
    earliest_end = min(end1, end2)
    delta = (earliest_end - latest_start).total_seconds()
    overlap = max(0, delta)
    return overlap

# Compute overlaps
df_cross['overlap'] = df_cross.apply(
    lambda row: compute_overlap(
        row['start'], row['end'],
        row['shift_start'], row['shift_end']
    ), axis=1
)

# Filter overlaps
df_overlaps = df_cross[df_cross['overlap'] > 0]

# Group by shift and status
df_grouped = df_overlaps.groupby(['shift_label', 'status_label'])['overlap'].sum().reset_index()

# Convert seconds to hours
df_grouped['overlap_hours'] = df_grouped['overlap'] / 3600  # Convert seconds to hours

# Pivot the data
df_pivot = df_grouped.pivot(index='shift_label', columns='status_label', values='overlap_hours').fillna(0)

# Plot the data
ax = df_pivot.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')








======================

# Generate date range
date_range = pd.date_range(start_date, end_date)

# Function to generate shift intervals
def generate_shift_intervals(df_shifts, date_range):
    shift_intervals = []
    for date in date_range:
        for idx, shift in df_shifts.iterrows():
            shift_label = shift['shift_label']
            shift_start = shift['shift_start']
            shift_end = shift['shift_end']
            shift_name = shift['shift']
            
            start_datetime = datetime.combine(date, shift_start)
            end_datetime = datetime.combine(date, shift_end)
            if shift_end <= shift_start:
                # Shift crosses midnight
                end_datetime += timedelta(days=1)
            shift_intervals.append({
                'shift': shift_name,
                'shift_label': f"{shift_label} ({date.date()})",
                'shift_start': start_datetime,
                'shift_end': end_datetime
            })
    return pd.DataFrame(shift_intervals)

# Generate shift intervals
df_shift_intervals = generate_shift_intervals(df_shifts, date_range)




============

print(df_shift_intervals[['shift_label', 'shift_start', 'shift_end']])



============



# Prepare for cross join
df_statuses['key'] = 1
df_shift_intervals['key'] = 1

# Cross join to combine statuses and shifts
df_cross = pd.merge(df_statuses, df_shift_intervals, on='key')

# Function to compute overlap
def compute_overlap(start1, end1, start2, end2):
    latest_start = max(start1, start2)
    earliest_end = min(end1, end2)
    delta = (earliest_end - latest_start).total_seconds()
    overlap = max(0, delta)
    return overlap

# Compute overlaps
df_cross['overlap'] = df_cross.apply(
    lambda row: compute_overlap(
        row['start'], row['end'],
        row['shift_start'], row['shift_end']
    ), axis=1
)

# Filter overlaps
df_overlaps = df_cross[df_cross['overlap'] > 0]




=======================

print(df_overlaps[['status_label', 'shift_label', 'overlap']].head())


==================================

# Group by shift and status
df_grouped = df_overlaps.groupby(['shift_label', 'status_label'])['overlap'].sum().reset_index()

# Convert seconds to hours
df_grouped['overlap_hours'] = df_grouped['overlap'] / 3600  # Convert seconds to hours

# Pivot the data
df_pivot = df_grouped.pivot(index='shift_label', columns='status_label', values='overlap_hours').fillna(0)



=========================


print(df_pivot)



=======================


import matplotlib.pyplot as plt

# Plot the data
ax = df_pivot.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')

# Customize the plot
plt.title('Total Machine Status Time per Shift')
plt.xlabel('Shift')
plt.ylabel('Hours')
plt.legend(title='Machine Status', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


=================================



import seaborn as sns

# Melt the pivoted DataFrame for seaborn
df_melted = df_pivot.reset_index().melt(id_vars='shift_label', var_name='status_label', value_name='hours')

# Plot using seaborn
plt.figure(figsize=(12, 8))
sns.barplot(data=df_melted, x='shift_label', y='hours', hue='status_label', palette='tab20', ci=None)

# Customize the plot
plt.title('Total Machine Status Time per Shift')
plt.xlabel('Shift')
plt.ylabel('Hours')
plt.legend(title='Machine Status', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


===================================






























